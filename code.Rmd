---
title: ""
author: "Sahitya Sundar Raj Vijayanagar (sv25849)"
output:
  pdf_document: default
  html_notebook: default
  html_document:
    df_print: paged
---
***
<center>
## Forecasting on US Electricity data using ARIMA
</center>
***

#### Problem Background: 

The file titled **US Electricity.csv** includes a time series index compiled by the US Federal Reserve representing total fossil-fuel US electricity generation by all utilities from January 1939 through October 2021.

In the following code box we read the CSV file and set up the data as a *tsibble* and then we plot it and subset it to examine it.

```{r}
library(fpp3)
library(tseries)

D <- read.csv("US Electricity.csv") %>% 
  mutate(DATE = yearmonth(DATE)) %>%
  as_tsibble(index = DATE)
  
D %>% autoplot(ELEC)

DR <- D %>% filter(DATE >= yearmonth("2010 Jan"))

DR %>% autoplot(ELEC)
```

We are interested in developing a two-year long monthly forecast (24 months) for the national electricity production requirements. 


1. First, we examine the stationarity of the **ELEC** time series in the reduced **DR** data, and also examine the corresponding ACF and PACF diagrams and then propose three plausible ARIMA models to fit the data.

**Solution:**
```{r, warning = FALSE}
DR %>% 
  mutate(diff.E = difference(ELEC),
         diff2.E = difference(diff.E)) -> DR

DR %>% autoplot(.vars = ELEC)
DR %>% autoplot(.vars = diff.E)
DR %>% autoplot(.vars = diff2.E)

# Examine Stationarity Visually
DR %>% ACF(ELEC) %>% 
  autoplot() + 
  labs(title = "Electricity")
DR %>% ACF(diff.E) %>% 
  autoplot() + 
  labs(title = "diff.E")
DR %>% ACF(diff2.E) %>% 
  autoplot() + 
  labs(title = "diff2.E")

# PACF
DR %>% PACF(ELEC) %>% 
  autoplot() + 
  labs(title = "Electricity")
DR %>% PACF(diff.E) %>% 
  autoplot() + 
  labs(title = "diff.E")
DR %>% PACF(diff2.E) %>% 
  autoplot() + 
  labs(title = "diff2.E")

```
Based on the above graphs, the time series looks stationary. The ACF and PACF show seasonality. 

We further conduct KPSS and ADF tests to confirm our initial understanding:
```{r, warning = FALSE}
DR %>% features(ELEC, unitroot_kpss)
DR %>% features(diff.E, unitroot_kpss)
DR %>% features(diff2.E, unitroot_kpss)

DR %>% features(ELEC, unitroot_ndiffs)


DR$ELEC %>% adf.test()

DR$diff.E %>%
  na.omit() %>%
  adf.test()

DR$diff2.E %>%
  na.omit() %>%
  adf.test()


```
Looking at the KPSS test p-value, it is greater than the threshold, hence we **fail to reject** the hypothesis, indicating that the time series is stationary. ## Null - stationary

According to the ADF test p-value, it is below the threshold, hence, we can **reject** the hypothesis. This also confirms that the time series is stationary.  ## Null - Not stationary

Seasonality in data with 3 strong PACF terms, suggesting the 3 ARIMA models with m=12:
**ARIMA1** : pdq(3,0,0)(1,1,0)[12]
**ARIMA2** : pdq(2,0,0)(1,1,0)[12]
**ARIMA3** : pdq(1,0,0)(1,1,0)[12]

2. Using **fable**, we fit the following five models to the **DR** data: (i)-(iii) the three models we proposed in (1), (iv) the automatically selected model by the ARIMA() function, and (v) the automatically selected model by the ETS() function.

```{r, warning = FALSE}
m <- DR %>% model(m1 = ARIMA(ELEC ~ pdq(3,0,0) + PDQ(1,1,0)),
    m2 = ARIMA(ELEC ~ pdq(2,0,0) + PDQ(1,1,0)),
    m3 = ARIMA(ELEC ~ pdq(1,0,0) + PDQ(1,1,0)),
    m4 = ARIMA(ELEC),
    m5 = ETS(ELEC))

m %>% glance() %>%
  select(.model, AICc, BIC)

```

Based on the above table, **m4** that is automatic ARIMA has the best model which is using ARIMA(1,0,0)(2,1,0)[12] 
as shown below:
```{r}
m %>% select(m4)%>%report()

```

  
3. We examine the residuals of all the models using the Ljung-Box test and the **gg_tsresiduals()** function.

```{r, warning = FALSE}
m %>% augment() %>%
  features(.resid, ljung_box, lag = 10)

m %>% select(m1) %>% gg_tsresiduals()
m %>% select(m2) %>% gg_tsresiduals()
m %>% select(m3) %>% gg_tsresiduals()
m %>% select(m4) %>% gg_tsresiduals()
m %>% select(m5) %>% gg_tsresiduals()

```
As shown above, we have high p values for the ARIMA models indicating that the residuals are uncorrelated.
Only the ETS model has low p value and the errors are correlated. This is also confirmed by the residual plots.

4. For the set of five models selected (automatically and/or manually), we examine the in-sample accuracy metrics.  Based on a holistic analysis of the information criteria, we select the best two ARIMA models and the ETS model. 

**Solution:**
```{r, warning = FALSE}
m %>% glance()%>%select(.model,AICc,BIC)
```
The two best ARIMA models are:
1. m4: ARIMA(1,0,0)(2,1,0)[12] AICc of 683.85
2. m3: ARIMA(1,0,0)(1,1,0)[12] AICc of 702.74
3. m2: ARIMA(2,0,0)(1,1,0)[12] AICc of 704.11
The ETS model is:
3. m5

**m4:**
```{r} 
m %>% select(m4)%>%report() # ETS
```

**m3:**
```{r} 
m %>% select(m3)%>%report() # ETS
```

**m2:**
```{r} 
m %>% select(m2)%>%report() # ETS
```

**ETS:**
```{r} 
m %>% select(m5)%>%report() # ETS
```

For model cross-validation purposes stretch the DR data as follows:
```{r, warning = FALSE}
D.CV <- DR %>%
  filter(DATE >= yearmonth("2010 Jan")) %>%
  stretch_tsibble(.init = 36, .step = 1)
```

5. Next, we fit cross-validation models for each of the time sub-series in the stretched data for each of the four model types selected in (4). In the case(s) where the models were automatically selected, we do not run the automatic selection under cross validation, instead we manually enter the model order/type when you call the ARIMA()/ETS() function. 

```{r, warning = FALSE}
mC <- D.CV %>%model( A1200110 = ARIMA(ELEC ~ pdq(2,0,0) + PDQ(1,1,0)),
    A2100110 = ARIMA(ELEC ~ pdq(1,0,0) + PDQ(1,1,0)),
    A3_Auto_100210= ARIMA(ELEC ~ pdq(1,0,0)+ PDQ(2,1,0)),
    E_Auto_MNA = ETS(ELEC ~ error("M") + trend("N") + season("A")))

```


6. Next, we prepare a 24-month ahead forecast for each of the models fitted in (5) and prepare a plot of MAPE vs months-ahead.  

```{r, warning = FALSE}
fc <- mC%>%forecast(h = 24)

fc2 <- fc%>%group_by(.id,.model) %>%
  mutate(h = row_number()) %>%
  ungroup()

fc2%>%accuracy(DR, by = c("h", ".model")) %>%
  ggplot(aes(x = h, y = MAPE,color = .model)) +
  geom_line()

```

We use cross-validation to validate the performance of our model. However, based on the above results, we see that ETS model performs poorly, hence, we discard it.

7. Below, we examine the cross-validation residuals of the models we selected in (6), and based on their correlation (model vs. model), we discuss if it is advisable to prepare an ensemble forecast averaging the forecasts of two or more models.

In order to make ensemble forecast, we look at the correlation of residuals. If the residuals are highly correlated, we do not prepare any ensemble forecasts, but if the residuals are not correlated, we prepare ensemble forecasts.
```{r, warning = FALSE}
x <- m %>% select(m4) %>% residuals()
y <- m %>% select(m3) %>% residuals()
z <- m %>% select(m2) %>% residuals()
cor(x$.resid,y$.resid)
cor(x$.resid,z$.resid)
cor(y$.resid,z$.resid)
```
As shown above, the residuals are quite high. Hence we would be building ensemble forecasts.

8. The index is very useful for energy planning purpose as most of the variability and seasonality is produced by combined cycle natural gas plants and single cycle  plants that also run on natural gas (i.e., nuclear and coal generation is fixed and relatively constant).  For this purpose it is of interest to know what is the production index level that will not be separated with a probability (service-level) of 95%. For the best model in (6), we plot the 24-month ahead forecast and plot the forecast and the corresponding confidence interval to help us address the service level question. Below, we report numerically the month-by-month the index forecasts that meet the desired 95% service level.

```{r, message=FALSE}
m_best <- DR%>%model(arima_best = ARIMA(ELEC ~ pdq(1,0,0) + PDQ(2,1,0)))
fc_best <- m_best%>%forecast(h=24)
fc_best%>%autoplot()+geom_line(data = D, mapping = aes(y = ELEC), col = "grey")
```


```{r, warning =FALSE}
fc_best%>%autoplot()
```

```{r, warning=FALSE}
fc_best %>%  hilo(level =c(90)) %>%
  unpack_hilo("90%") %>%
  select(ELEC,"90%_upper")
```
